Tasks:

- Take off-the-shelf linear model to make the classification and have it as a form of baseline

- Finish implementing paper

- If time permits it: look into bayesian approaches

Questions for Michael:

- Check if batch norm is performed correctly


Hypotheses for overfitting:
 - Dropout not deactivated in eval mode -> should be covered with model.eval() - try also setting inplace=False in dropouts (just in case)
 - Too small batchsize
 - Data loading could be done incorrectly?
 - Could be that there's class imbalance between train and test
 - Keep 21 classes 


Implement Deep ensemble followed by SWAG   + Look at accuraty and calibration once done
Save for 50 models

Separate in a different function the inference, and then build a conventional test and swag multi-swag test.

compute LPD and expected calibration error (uncertainty toolbox might help). https://github.com/uncertainty-toolbox/uncertainty-toolbox 

Merge all the fold plots to a single one with average value and error bars (standard error = standard dev. / sqrt(N folds))

Confidence metric or entropy of the distribution in order to account for uncertainty.

In Average fold plot make points for individual models + dashed line for average

Do SWAG.
